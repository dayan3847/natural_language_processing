{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMa8cc0HVnKTP1tvPpnihNB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hbZqNvfjftw2","executionInfo":{"status":"ok","timestamp":1678244774644,"user_tz":360,"elapsed":1089,"user":{"displayName":"Dayan Bravo Fraga","userId":"05762651316564612225"}},"outputId":"2987c0b3-30c0-4974-a1ba-23bf6be306f4"},"outputs":[{"output_type":"stream","name":"stdout","text":["rm: cannot remove './corpus': No such file or directory\n","Cloning into 'mcc_nlp_task_nap'...\n","remote: Enumerating objects: 91, done.\u001b[K\n","remote: Counting objects: 100% (91/91), done.\u001b[K\n","remote: Compressing objects: 100% (85/85), done.\u001b[K\n","remote: Total 91 (delta 5), reused 89 (delta 3), pack-reused 0\u001b[K\n","Unpacking objects: 100% (91/91), 837.13 KiB | 6.64 MiB/s, done.\n"]}],"source":["! rm -R ./mcc_nlp_task_nap\n","! rm -R ./corpus\n","! git clone https://github.com/dayan3847/mcc_nlp_task_nap\n","! cp -R ./mcc_nlp_task_nap/corpus/ ./\n","\n","# ! python -m spacy download es_core_news_sm"]},{"cell_type":"code","source":["from networkx import Graph\n","from typing import List\n","from matplotlib import pyplot as plt\n","import os\n","import nltk\n","import xlrd\n","import networkx as nx"],"metadata":{"id":"sv_soxxoL69E","executionInfo":{"status":"ok","timestamp":1678244923939,"user_tz":360,"elapsed":5,"user":{"displayName":"Dayan Bravo Fraga","userId":"05762651316564612225"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["nltk.download('stopwords')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"di0RGl5_NC2f","executionInfo":{"status":"ok","timestamp":1678245119092,"user_tz":360,"elapsed":243,"user":{"displayName":"Dayan Bravo Fraga","userId":"05762651316564612225"}},"outputId":"bb5add94-dd5f-4b8b-914c-b73e2b784c2a"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["class Graphs:\n","\n","    def __init__(self):\n","        self.graph_frequency = Graph()\n","        self.graph_time = Graph()\n","        self.graph_association = Graph()\n"],"metadata":{"id":"VD2WIreCL7y8","executionInfo":{"status":"ok","timestamp":1678244830009,"user_tz":360,"elapsed":6,"user":{"displayName":"Dayan Bravo Fraga","userId":"05762651316564612225"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["class Definition:\n","\n","    def __init__(self):\n","        self.word_input: str = ''\n","        self.word_outputs: List[List[str]] = []\n"],"metadata":{"id":"tm4lz6Q7L_k9","executionInfo":{"status":"ok","timestamp":1678244846313,"user_tz":360,"elapsed":6,"user":{"displayName":"Dayan Bravo Fraga","userId":"05762651316564612225"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["\n","class DataSet:\n","\n","    def __init__(self):\n","        self.graphs: Graphs | None = None\n","        self.definitions: List[Definition] = []\n","        self.path_file_nap: str = './corpus/NAP.xls'\n","        self.path_folder_definitions: str = './corpus/freeling_definitions/'\n","        self.ignore_words: List[str] = ['--PALABRAS--', '', '=', '*']\n","\n","    def import_graphs(self):\n","        if self.graphs is not None:\n","            return self.graphs\n","\n","        self.graphs = Graphs()\n","        workbook = xlrd.open_workbook(self.path_file_nap)\n","        sheet = workbook.sheet_by_index(0)\n","        count_rows = sheet.nrows\n","        word_input: str = ''\n","        for row in range(count_rows):\n","            cell = sheet.cell(row, 0)\n","            cell_value: str = str(cell.value).strip()\n","            if '======' == cell_value:\n","                word_input = ''\n","                continue\n","            elif cell_value in self.ignore_words:\n","                continue\n","            elif '' == word_input:\n","                word_input = cell_value\n","            else:\n","                # frequency\n","                frequency: float = float(sheet.cell(row, 1).value)\n","                frequency_weight: float = 1 / frequency\n","                self.graphs.graph_frequency.add_edge(word_input, cell_value, weight=frequency_weight)\n","                # time\n","                time: float = float(sheet.cell(row, 2).value)\n","                self.graphs.graph_time.add_edge(word_input, cell_value, weight=time)\n","                # association\n","                association: float = float(sheet.cell(row, 3).value)\n","                association_weight: float = 100 - association\n","                self.graphs.graph_association.add_edge(word_input, cell_value, weight=association_weight)\n","        return self.graphs\n","\n","    def clean_lematize(self, sentence: str):\n","        sentence = sentence.strip()\n","        result: str = ''\n","        stopwords = nltk.corpus.stopwords.words('spanish')\n","        words = sentence.split()\n","        for word in words:\n","            if word in stopwords:\n","                continue\n","            # doc = nlp(word)\n","            # result += doc[0].lemma_+ \" \"\n","            result += word + ' '\n","        return result\n","\n","    def import_definitions(self) -> List[Definition]:\n","        if len(self.definitions) > 0:\n","            return self.definitions\n","        directory: str = self.path_folder_definitions\n","        self.definitions: List[Definition] = []\n","        for file_name in os.listdir(directory):\n","            if not file_name.endswith('.txt'):\n","                continue\n","\n","            file_data = open(directory + file_name, encoding=\"utf8\")\n","            lines = file_data.readlines()\n","            definition = Definition()\n","            definition.word_input = str(lines[0]).lower().strip()\n","            for line in lines[1:]:\n","                line = line.strip()\n","                if '' == line:\n","                    continue\n","                line = self.clean_lematize(line)\n","                definition.word_outputs.append(line.split())\n","            self.definitions.append(definition)\n","\n","        return self.definitions\n"],"metadata":{"id":"t9xquxp1MIAM","executionInfo":{"status":"ok","timestamp":1678244874883,"user_tz":360,"elapsed":269,"user":{"displayName":"Dayan Bravo Fraga","userId":"05762651316564612225"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["\n","\n","def draw(graph: nx.Graph):\n","    nx.draw(\n","        graph,\n","        with_labels=True,\n","        font_weight='bold',\n","        node_size=1000,\n","        node_color='green',\n","    )\n","    plt.show()\n"],"metadata":{"id":"DMzyNxH-MX2z","executionInfo":{"status":"ok","timestamp":1678244943310,"user_tz":360,"elapsed":258,"user":{"displayName":"Dayan Bravo Fraga","userId":"05762651316564612225"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["\n","def reduce_graph(graph: nx.Graph, subset: list) -> nx.Graph:\n","    sub_graph = nx.Graph()\n","    for node in subset:\n","        if node not in graph.nodes():\n","            continue\n","        for neighbor in graph.neighbors(node):\n","            weight = graph[node][neighbor]['weight']\n","            sub_graph.add_edge(node, neighbor, weight=weight)\n","    return sub_graph\n"],"metadata":{"id":"-yXd9vcFMc1q","executionInfo":{"status":"ok","timestamp":1678244960007,"user_tz":360,"elapsed":262,"user":{"displayName":"Dayan Bravo Fraga","userId":"05762651316564612225"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["\n","def bt_centrality(graph: nx.Graph, subset: List[str]) -> dict:\n","    sub_graph = reduce_graph(graph, subset)\n","    result = nx.betweenness_centrality(sub_graph, normalized=True, weight=\"weight\")\n","    for w in subset:\n","        if w in result:\n","            result.pop(w)\n","    result = dict(sorted(result.items(), key=lambda item: item[1], reverse=True))\n","    return result\n"],"metadata":{"id":"bPW0fSAcMZt6","executionInfo":{"status":"ok","timestamp":1678244961637,"user_tz":360,"elapsed":249,"user":{"displayName":"Dayan Bravo Fraga","userId":"05762651316564612225"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["\n","\n","def build_definitions_graph(graphs: Graphs, definitions: List[Definition]):\n","    for definition in definitions:\n","        print('\\033[32m' + f'Input: {definition.word_input}' + '\\033[0m')\n","        for word_output in definition.word_outputs:\n","            print('\\033[33m' + f'Output: {word_output}' + '\\033[0m')\n","            sub_graph = reduce_graph(graphs.graph_frequency, word_output)\n","            print('Frequency ' + str(sub_graph))\n","            btc = bt_centrality(sub_graph, word_output)\n","            print('\\033[35m' + str(btc) + '\\033[0m')\n","            draw(sub_graph)\n","            sub_graph = reduce_graph(graphs.graph_time, word_output)\n","            print('Time ' + str(sub_graph))\n","            btc = bt_centrality(sub_graph, word_output)\n","            print('\\033[35m' + str(btc) + '\\033[0m')\n","            draw(sub_graph)\n","            sub_graph = reduce_graph(graphs.graph_association, word_output)\n","            print('Association ' + str(sub_graph))\n","            btc = bt_centrality(sub_graph, word_output)\n","            print('\\033[35m' + str(btc) + '\\033[0m')\n","            draw(sub_graph)\n"],"metadata":{"id":"J9kCRCNbMiFG","executionInfo":{"status":"ok","timestamp":1678245074052,"user_tz":360,"elapsed":628,"user":{"displayName":"Dayan Bravo Fraga","userId":"05762651316564612225"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["\n","if __name__ == '__main__':\n","    data_set = DataSet()\n","    # Import Graphs\n","    the_graphs = data_set.import_graphs()\n","    print('Frequency ' + str(the_graphs.graph_frequency))\n","    print('Time ' + str(the_graphs.graph_time))\n","    print('Association ' + str(the_graphs.graph_association))\n","    # Import Definitions\n","    the_definitions = data_set.import_definitions()\n","    print('Definitions ' + str(the_definitions))\n","    # Build Graphs\n","    build_definitions_graph(the_graphs, the_definitions)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1p_UqurBTGEKYBLyqs3pcc-Qq7CBVQJLD"},"id":"rnJDweptM75t","executionInfo":{"status":"ok","timestamp":1678245690487,"user_tz":360,"elapsed":565378,"user":{"displayName":"Dayan Bravo Fraga","userId":"05762651316564612225"}},"outputId":"e163c83b-19eb-4907-b05d-59c2159e3c81"},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}