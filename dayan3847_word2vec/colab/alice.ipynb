{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Universidad Autónoma de Yucatán\n",
    "\n",
    "## Facultad de Matemáticas\n",
    "\n",
    "### Natural Language Processing\n",
    "\n",
    "**Teacher:** Dr. Jorge Carlos Reyes\n",
    "\n",
    "**Student:** Dayan Bravo Fraga"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Word2vec"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Alice"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Clone and load project from GitHub (only for Colab)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "in_colab: bool = 'google.colab' in sys.modules\n",
    "if in_colab:\n",
    "    print('Is running in Colab')\n",
    "    # mount drive\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount('/content/drive')\n",
    "    if not os.path.isdir('natural_language_processing'):\n",
    "        print(\"Downloading project\")\n",
    "        ! git clone https://github.com/dayan3847/natural_language_processing\n",
    "        sys.path.insert(0, './natural_language_processing/')\n",
    "    else:\n",
    "        ! git -C ./natural_language_processing fetch\n",
    "        ! git -C ./natural_language_processing rebase\n",
    "else:\n",
    "    print('Is not running in Colab')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Config"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "root_path: str = './../' if not in_colab else './natural_language_processing/dayan3847_word2vec/'\n",
    "root_path_corpus: str = os.path.join(root_path, 'corpus/')\n",
    "root_path_results: str = './../emb/'\n",
    "print('root_path_corpus:', root_path_corpus)\n",
    "print('root_path_results:', root_path_results)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import gensim\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nltk.download('punkt')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "example_name = \"alice.txt\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_example = open(root_path_corpus + example_name, \"r\", encoding=\"utf8\")\n",
    "text_example = file_example.read()\n",
    "text_example[:100]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#replaces escape character with space\n",
    "text_example = text_example.replace(\"\\n\", \" \")\n",
    "text_example[:100]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_data_from_test(text):\n",
    "    data = []\n",
    "    # iterate through each sentence in the file\n",
    "    for i in sent_tokenize(text):\n",
    "        temp = []\n",
    "        # tokenize the sentence into words\n",
    "        for j in word_tokenize(i):\n",
    "            temp.append(j.lower())\n",
    "        data.append(temp)\n",
    "\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "example_data = get_data_from_test(text_example)\n",
    "example_data[0][:3]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create CBOW model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create CBOW model\n",
    "def create_cbow_model(data, file_name_to_save: str = ''):\n",
    "    model = gensim.models.Word2Vec(data, min_count=1, vector_size=300, window=5)\n",
    "    if file_name_to_save != '':\n",
    "        word_vectors = model.wv\n",
    "        word_vectors.save_word2vec_format(f\"{root_path_results}{file_name_to_save}.cbow.emb\", binary=False)\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_cbow = create_cbow_model(example_data, example_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Skip Gram model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create Skip Gram model\n",
    "def create_skip_gram_model(data, file_name_to_save: str = ''):\n",
    "    model = gensim.models.Word2Vec(data, min_count=1, vector_size=300, window=5, sg=1)\n",
    "    if file_name_to_save != '':\n",
    "        word_vectors = model.wv\n",
    "        word_vectors.save_word2vec_format(f\"{root_path_results}{file_name_to_save}.skip_gram.emb\", binary=False)\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_skip_gram = create_skip_gram_model(example_data, example_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tests"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_cbow.wv.similarity('alice', 'machines')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_skip_gram.wv.similarity('alice', 'machines')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save in Drive (only for Colab)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if in_colab:\n",
    "    emb_path: str = str(input('') or './drive/MyDrive/emb/')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
